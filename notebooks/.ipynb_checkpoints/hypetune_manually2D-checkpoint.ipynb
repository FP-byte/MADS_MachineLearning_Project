{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.129'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "import tomllib\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "import math\n",
    "from typing import List, Tuple, Dict, Any, Union\n",
    "from src import datasets, metrics\n",
    "import mltrainer\n",
    "import mlflow\n",
    "from src import models\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "mltrainer.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrixs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, teststreamer):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    #model = model.to(\"cpu\")\n",
    "\n",
    "    #testdata = [(x.to(device), y.to(device)) for x, y in teststreamer.stream()]\n",
    "    testdata = teststreamer.stream()\n",
    "    for _ in range(len(teststreamer)):\n",
    "        X, y = next(testdata)\n",
    "\n",
    "        yhat = model(X)\n",
    "        yhat = yhat.argmax(dim=1) # we get the one with the highest probability\n",
    "        y_pred.append(yhat.cpu().tolist())\n",
    "        y_true.append(y.cpu().tolist())\n",
    "\n",
    "    yhat = [x for y in y_pred for x in y]\n",
    "    y = [x for y in y_true for x in y]\n",
    "    return y, yhat\n",
    "\n",
    "def plot_confusion_matrix(cfm, model_name):\n",
    "    # Create the plot using seaborn\n",
    "    plot = sns.heatmap(cfm, annot=True, fmt=\".3f\")\n",
    "    \n",
    "    # Set the labels for the axes\n",
    "    plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n",
    "    \n",
    "    # Save the plot to a file with the model name in the filename\n",
    "    plt.savefig(f\"{model_name}_confusion_matrix.png\", bbox_inches=\"tight\")\n",
    "    \n",
    "    # Optionally, display the plot\n",
    "    plt.show()\n",
    "\n",
    "# difference between test and train\n",
    "def calculate_difference(train_scores_str, test_scores_str):\n",
    "    # Remove the brackets and split the string by spaces\n",
    "    str_list = test_scores_str.strip('[]').split()\n",
    "\n",
    "    # Convert each element to a float\n",
    "    test_scores_str = [float(num) for num in str_list]\n",
    "\n",
    "    test_scores = [float(x) for x in test_scores_str]\n",
    "    train_scores = [float(x) for x in train_scores_str]\n",
    "    difference = [str(np.round(test - train, 3)) for test, train in zip(test_scores, train_scores)]\n",
    "    print(f'train loss average:{np.round(np.mean(test_scores), 3)}')\n",
    "    print(f'test loss average:{np.round(np.mean(test_scores), 3)}')\n",
    "\n",
    "    return difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainstreamer, teststreamer, config, settings=None):\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            optimizer = torch.optim.Adam\n",
    "\n",
    "            if settings==None:\n",
    "                # default settings\n",
    "                settings = TrainerSettings(\n",
    "                    epochs=15,\n",
    "                    metrics=[accuracy, f1micro, f1macro, precision, recall],\n",
    "                    logdir=\"logs/heart2D_oversampled\",\n",
    "                    train_steps=len(trainstreamer) // 5,\n",
    "                    valid_steps=len(teststreamer) // 5,\n",
    "                    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "                    scheduler_kwargs={\"factor\": 0.5, \"patience\": 2},\n",
    "                    earlystop_kwargs={\"patience\": 8},\n",
    "                )\n",
    "            if config['traindataset'] =='smote':\n",
    "                    logdir=\"logs/heart2D_smote\",\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                settings=settings,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                traindataloader=trainstreamer.stream(),\n",
    "                validdataloader=teststreamer.stream(),\n",
    "                scheduler= config[\"scheduler\"],\n",
    "            )\n",
    "\n",
    "            mlflow.set_tag(\"model\", config[\"model\"])\n",
    "            mlflow.set_tag(\"dataset\", \"heart_big_oversampled\")\n",
    "            mlflow.log_param(\"scheduler\", str(trainer.scheduler).split(\".\")[-1])\n",
    "            mlflow.log_param(\"earlystop\", str(settings.earlystop_kwargs))\n",
    "\n",
    "            base_config = {\n",
    "                \"hidden\": config[\"hidden\"],\n",
    "                \"dropout\": config[\"dropout\"],\n",
    "                \"num_classes\": config[\"num_classes\"],\n",
    "                \"num_heads\": config[\"num_heads\"],\n",
    "                \"num_blocks\": config[\"num_blocks\"],\n",
    "                \"shape\": config[\"shape\"],\n",
    "  \n",
    "            }\n",
    "            mlflow.log_params(base_config)\n",
    "            mlflow.log_param(\"epochs\", settings.epochs)\n",
    "            mlflow.log_param(\"shape0\", config[\"shape\"])\n",
    "            mlflow.log_param(\"optimizer\", str(optimizer))\n",
    "            mlflow.log_params(settings.optimizer_kwargs)\n",
    "            trainer.loop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ptb': 'heart', 'arrhythmia': 'heart_big'}\n",
      "MPS is available\n"
     ]
    }
   ],
   "source": [
    "datadir = Path('../data')\n",
    "configfile = Path(\"config.toml\")\n",
    "\n",
    "with configfile.open('rb') as f:\n",
    "    config = tomllib.load(f)\n",
    "print(config)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "            device = torch.device('mps')\n",
    "            print('MPS is available')\n",
    "else:\n",
    "            device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('../data/heart_big_oversampled_full_train.parq'),\n",
       " PosixPath('../data/heart_big_test.parq'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choos dataset\n",
    "trainfile = datadir / (config['arrhythmia'] + '_oversampled_full_train.parq')\n",
    "#trainfile = datadir / (config['arrhythmia'] + '_SMOTE_train.parq')\n",
    "testfile = datadir / (config['arrhythmia'] + '_test.parq')\n",
    "\n",
    "trainfile, testfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2D models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Heartdataset2D (#275000), Heartdataset2D (#21892))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load 2D dataset with shape = (16, 12)\n",
    "shape = (16, 12)\n",
    "traindataset = datasets.HeartDataset2D(trainfile, target=\"target\", shape=shape)\n",
    "testdataset = datasets.HeartDataset2D(testfile, target=\"target\", shape=shape)\n",
    "traindataset, testdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8593, 684)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = BaseDatastreamer(traindataset, preprocessor = BasePreprocessor(), batchsize=32)\n",
    "teststreamer = BaseDatastreamer(testdataset, preprocessor = BasePreprocessor(), batchsize=32)\n",
    "len(trainstreamer), len(teststreamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load settings\n",
    "f1micro = metrics.F1Score(average='micro')\n",
    "f1macro = metrics.F1Score(average='macro')\n",
    "precision = metrics.Precision('micro')\n",
    "recall = metrics.Recall('macro')\n",
    "accuracy = metrics.Accuracy()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "        epochs=15,\n",
    "        metrics=[accuracy, f1micro, f1macro, precision, recall],\n",
    "        logdir=\"logs/heart2D_oversampled\",\n",
    "        train_steps=len(trainstreamer) // 5, #met 5 epochs heeft het een keer de hele dataset gezien\n",
    "        valid_steps=len(teststreamer) // 5,\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "        scheduler_kwargs={\"factor\": 0.5, \"patience\": 2},\n",
    "        earlystop_kwargs= {\"patience\": 8},\n",
    "        device= device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-01 20:57:09.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mActivation map size: 48\u001b[0m\n",
      "\u001b[32m2025-02-01 20:57:09.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mInput linear: 6144\u001b[0m\n",
      "\u001b[32m2025-02-01 20:57:09.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to logs/heart2D_oversampled/20250201-205709\u001b[0m\n",
      "\u001b[32m2025-02-01 20:57:09.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'CNN2D', 'scheduler': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'input': 1, 'hidden': 128, 'num_layers': 2, 'dropout': 0.2, 'num_classes': 5, 'num_blocks': 2, 'shape': (16, 12), 'num_heads': 8, 'traindataset': 'oversampled'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[38;2;30;71;6m                                                                                                                                                        \u001b[0m| 0/15 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m                                                                                                                                                      \u001b[0m| 0/1718 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m                                                                                                                                              \u001b[0m| 1/1718 [00:00<03:56,  7.26it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▏                                                                                                                                             \u001b[0m| 2/1718 [00:00<03:53,  7.35it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▏                                                                                                                                             \u001b[0m| 3/1718 [00:00<03:57,  7.23it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▎                                                                                                                                             \u001b[0m| 4/1718 [00:00<03:55,  7.28it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▍                                                                                                                                             \u001b[0m| 5/1718 [00:00<03:48,  7.49it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▍                                                                                                                                             \u001b[0m| 6/1718 [00:00<03:45,  7.59it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▌                                                                                                                                             \u001b[0m| 7/1718 [00:00<03:45,  7.59it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▋                                                                                                                                             \u001b[0m| 8/1718 [00:01<03:44,  7.62it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▋                                                                                                                                             \u001b[0m| 9/1718 [00:01<03:40,  7.74it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▊                                                                                                                                            \u001b[0m| 10/1718 [00:01<03:39,  7.76it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▉                                                                                                                                            \u001b[0m| 11/1718 [00:01<03:38,  7.82it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m▉                                                                                                                                            \u001b[0m| 12/1718 [00:01<03:38,  7.80it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█                                                                                                                                            \u001b[0m| 13/1718 [00:01<03:40,  7.75it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▏                                                                                                                                           \u001b[0m| 14/1718 [00:01<03:39,  7.75it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▏                                                                                                                                           \u001b[0m| 15/1718 [00:01<03:38,  7.78it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▎                                                                                                                                           \u001b[0m| 16/1718 [00:02<03:37,  7.82it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▍                                                                                                                                           \u001b[0m| 17/1718 [00:02<03:37,  7.81it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▍                                                                                                                                           \u001b[0m| 18/1718 [00:02<03:42,  7.65it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▌                                                                                                                                           \u001b[0m| 19/1718 [00:02<03:40,  7.70it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▋                                                                                                                                           \u001b[0m| 20/1718 [00:02<03:41,  7.65it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▋                                                                                                                                           \u001b[0m| 21/1718 [00:02<03:42,  7.62it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▊                                                                                                                                           \u001b[0m| 22/1718 [00:02<03:40,  7.70it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▉                                                                                                                                           \u001b[0m| 23/1718 [00:03<03:51,  7.32it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m█▉                                                                                                                                           \u001b[0m| 24/1718 [00:03<03:46,  7.48it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m██                                                                                                                                           \u001b[0m| 25/1718 [00:03<03:41,  7.63it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m██▏                                                                                                                                          \u001b[0m| 26/1718 [00:03<03:39,  7.72it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m██▏                                                                                                                                          \u001b[0m| 27/1718 [00:03<03:41,  7.64it/s]\u001b[0m\n",
      "\u001b[A%|\u001b[38;2;30;71;6m██▎                                                                                                                                          \u001b[0m| 28/1718 [00:03<03:42,  7.60it/s]\u001b[0m\n",
      "  2%|\u001b[38;2;30;71;6m██▍                                                                                                                                          \u001b[0m| 29/1718 [00:03<03:42,  7.59it/s]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                                                                        \u001b[0m| 0/15 [00:03<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///mads_exam.db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainstreamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteststreamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m y, yhat \u001b[38;5;241m=\u001b[39m test_model(model, teststreamer)\n\u001b[1;32m     28\u001b[0m cfm \u001b[38;5;241m=\u001b[39m confusion_matrix(y, yhat)\n",
      "Cell \u001b[0;32mIn[30], line 52\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(trainstreamer, teststreamer, config, settings)\u001b[0m\n\u001b[1;32m     50\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(optimizer))\n\u001b[1;32m     51\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(settings\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:90\u001b[0m, in \u001b[0;36mTrainer.loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloop\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mepochs), colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#1e4706\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 90\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m         metric_dict, test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevalbatches()\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(epoch, train_loss, test_loss, metric_dict)\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:120\u001b[0m, in \u001b[0;36mTrainer.trainbatches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 120\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(yhat, y)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    122\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/src/models.py:50\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvolutions:\n\u001b[0;32m---> 50\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(x)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/src/models.py:20\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code_repo/MADS-exam-25/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelname= \"CNN2D\"\n",
    "config = {\n",
    "    \"model\": modelname,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"input\": 1,\n",
    "    \"hidden\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_classes\": 5,\n",
    "    \"num_blocks\": 2,\n",
    "    \"num_classes\": 5,\n",
    "    \"shape\": (16, 12),\n",
    "    \"num_heads\": 8,\n",
    "    \"traindataset\": \"oversampled\",\n",
    "    \n",
    "}\n",
    "if 'smote' in str(trainfile):\n",
    "    config['traindataset'] = 'smote'\n",
    "\n",
    "\n",
    "\n",
    "print(config)\n",
    "model = models.CNN(config)\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(config[\"model\"])\n",
    "train_model(trainstreamer, teststreamer, config, settings)\n",
    "y, yhat = test_model(model, teststreamer)\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "confusion_matrixs[modelname] = cfm\n",
    "print(config)\n",
    "plot_confusion_matrix(cfm, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2CNN WITH RESNET BLOCK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "Resnet block would help the CNN to avoid overfitting the data\n",
    "ResNet block consists of two convolutions with batch normalization, ReLU activation, and a skip connection that adds the input back to the output.\n",
    "Hypthesis: the ResNet block would help with longer training, supporting the gradient and learning of more complex representations.\n",
    "2D CNN: Good at extracting local spatial features from the data (like images or spatial sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname= \"CNN2DResNet\"\n",
    "config = {\n",
    "    \"model\": modelname,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"input\": 1,\n",
    "    \"hidden\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_classes\": 5,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_blocks\": 1,\n",
    "    \"num_classes\": 5,\n",
    "    \"shape\": (16, 12),\n",
    "    'traindataset': 'oversampled'\n",
    "}\n",
    "if 'smote' in str(trainfile):\n",
    "    config['traindataset'] = 'smote'\n",
    "\n",
    "print(config)\n",
    "model = models.CNN2DResNet(config)\n",
    "print(model)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(config[\"model\"])\n",
    "train_model(trainstreamer, teststreamer, config, settings)\n",
    "y, yhat = test_model(model, teststreamer)\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "confusion_matrixs[modelname] = cfm\n",
    "print(config)\n",
    "plot_confusion_matrix(cfm, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMER MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORMER 2D\n",
    "\n",
    "Changed Transformer with 1D cnn to Transformer with 2D CNN\n",
    "Because the Transformer with 1D CNN is performing below expectation, 2D CNN might help the learning of features in minority classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname= \"Transformer2D\"\n",
    "config = {\n",
    "    \"model\": modelname,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"input\": 1,\n",
    "    \"hidden\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_classes\": 5,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_blocks\": 1,\n",
    "    \"num_classes\": 5,\n",
    "    \"shape\": (16, 12),\n",
    "    'traindataset': 'oversampled'\n",
    "   \n",
    "}\n",
    "if 'smote' in str(trainfile):\n",
    "    config['traindataset'] = 'smote'\n",
    "\n",
    "print(config)\n",
    "model = models.Transformer2D(config)\n",
    "print(model)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(config[\"model\"])\n",
    "train_model(trainstreamer, teststreamer, config, settings)\n",
    "y, yhat = test_model(model, teststreamer)\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "confusion_matrixs[modelname] = cfm\n",
    "print(config)\n",
    "plot_confusion_matrix(cfm, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRANSFORMER 2D WITH RESNET BLOCK\n",
    "Adding a ResNet block to a Transformer has several advantages:\n",
    "\n",
    "Improved gradient flow, leading to more stable training and easier optimization.\n",
    "The model can learn richer and more complex features.\n",
    "Better regularization and reduced risk of overfitting.\n",
    "Reduced training time, scale up models without degrading performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname= \"Transformer2DResNet\"\n",
    "config = {\n",
    "    \"model\": modelname,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"hidden\": 128,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_classes\": 5,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_blocks\": 1,\n",
    "    \"num_classes\": 5,\n",
    "    \"shape\": (16, 12),\n",
    "    'traindataset': 'oversampled'\n",
    "   \n",
    "}\n",
    "if 'smote' in str(trainfile):\n",
    "    config['traindataset'] = 'smote'\n",
    "    \n",
    "print(config)\n",
    "model = models.Transformer2DResNet(config)\n",
    "print(model)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(config[\"model\"])\n",
    "train_model(trainstreamer, teststreamer, config, settings)\n",
    "y, yhat = test_model(model, teststreamer)\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "confusion_matrixs[modelname] = cfm\n",
    "print(config)\n",
    "plot_confusion_matrix(cfm, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRANSFORMER WITH SQUEEZE AND EXCITE BLOCK\n",
    "\n",
    "Squeeze-and-Excitation (SE) block: \n",
    "Squeeze: It computes global statistics (e.g., global average pooling) across the feature maps, summarizing the channel-wise information into a compact representation.\n",
    "Excite: The resulting compact representation is passed through a small fully connected network (usually with activation functions like ReLU and Sigmoid) to generate channel-wise attention weights that modify (recalibrate) the original feature map.\n",
    "\n",
    "In a Transformer: Adding SE blocks to a Transformer can help recalibrate the features extracted by the attention mechanism. Specifically, each channel (or attention head) can learn to focus on more important features while suppressing less important ones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelname= \"Transformer2DResNetSE\"\n",
    "config = {\n",
    "    \"model\": modelname,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"hidden\": 128,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_classes\": 5,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_blocks\": 1,\n",
    "    \"num_classes\": 5,\n",
    "    \"shape\": (16, 12),\n",
    "    'traindataset': 'oversampled'\n",
    "   \n",
    "}\n",
    "if 'smote' in str(trainfile):\n",
    "    config['traindataset'] = 'smote'\n",
    "    \n",
    "print(config)\n",
    "model = models.Transformer2DResNetSE(config)\n",
    "print(model)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(config[\"model\"])\n",
    "train_model(trainstreamer, teststreamer, config, settings)\n",
    "y, yhat = test_model(model, teststreamer)\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "confusion_matrixs[modelname] = cfm\n",
    "confusion_matrixs[modelname] = cfm\n",
    "\n",
    "print(config)\n",
    "plot_confusion_matrix(cfm, modelname)plot_confusion_matrix(cfm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFORMER + CNN 2D + RESNET + SE + MULTIHEAD\n",
    "\n",
    "IDEA:\n",
    "Conv2D: Extracts low-level spatial features.\n",
    "ResNet block: Enables deep learning via residual connections.\n",
    "Squeeze-and-Excite: Recalibrates feature maps to emphasize important channels.\n",
    "Positional Encoding: Adds positional information to the sequence for the transformer.\n",
    "Transformer Blocks: Captures long-range dependencies and complex relationships.\n",
    "Global Pooling: Reduces the sequence output to a fixed-size representation.\n",
    "Multi head attention: This mechanism allows the model to focus on different parts of the sequence simultaneously, learning multiple relationships between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelname= \"Transformer2DResNetWithAttention\"\n",
    "config = {\n",
    "    \"model\": modelname,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"hidden\": 128,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_classes\": 5,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_blocks\": 1,\n",
    "    \"num_classes\": 5,\n",
    "    \"shape\": (16, 12),\n",
    "    'traindataset': 'oversampled'\n",
    "   \n",
    "}\n",
    "if 'smote' in str(trainfile):\n",
    "    config['traindataset'] = 'smote'\n",
    "print(config)\n",
    "model = models.Transformer2DResNetWithAttention(config)\n",
    "print(model)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(config[\"model\"])\n",
    "train_model(trainstreamer, teststreamer, config, settings)\n",
    "y, yhat = test_model(model, teststreamer)\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "confusion_matrixs[modelname] = cfm\n",
    "print(config)\n",
    "plot_confusion_matrix(cfm, modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
